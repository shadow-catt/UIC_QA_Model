{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd43b0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from datasets import list_metrics,load_metric\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47de3bfc",
   "metadata": {},
   "source": [
    "# Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8288639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(y_ture,y_pred):\n",
    "    f1_metric = load_metric(\"f1\")\n",
    "    re_metric = load_metric(\"recall\")\n",
    "    pre_metric = load_metric(\"precision\")\n",
    "    type_c_int = list(set(np.concatenate([y_ture, y_pred])))\n",
    "    type_c = [str(i) for i in type_c_int]\n",
    "    \n",
    "    f1_m_list = []\n",
    "    re_m_list = []\n",
    "    pre_m_list = []\n",
    "    \n",
    "    for i in type_c_int:\n",
    "        bi_ture = list(y_ture == i)\n",
    "        bi_pred = list(y_pred == i)\n",
    "        f1_m_results = f1_metric.compute(predictions=bi_pred, references=bi_ture, average=\"macro\")\n",
    "        re_m_results = re_metric.compute(predictions=bi_pred, references=bi_ture, average=\"macro\")\n",
    "        pre_m_results = pre_metric.compute(predictions=bi_pred, references=bi_ture, average=\"macro\")\n",
    "        \n",
    "        f1_m_list.append(f1_m_results[\"f1\"])\n",
    "        re_m_list.append(re_m_results[\"recall\"])\n",
    "        pre_m_list.append(pre_m_results[\"precision\"])\n",
    "        \n",
    "    data = {'Class_type':type_c_int,'F1-macro':f1_m_list,'Recall-macro':re_m_list,'Precision-macro':pre_m_list}\n",
    "    df = pd.DataFrame(data)\n",
    "    display(df)\n",
    "    \n",
    "    \n",
    "    z = confusion_matrix(y_ture, y_pred)\n",
    "    x_lab = type_c\n",
    "\n",
    "    fig = px.imshow(z, \n",
    "                    text_auto=True,\n",
    "                    labels=dict(x=\"True label\", y=\"Predicted label\", color=\"times\"),\n",
    "                    x=x_lab,\n",
    "                    y=x_lab)\n",
    "#     fig.show()\n",
    "    \n",
    "    return z,fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27532de",
   "metadata": {},
   "source": [
    "# Loading the data for use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a58a2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U sentence-transformers\n",
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d1a4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from random import randint,shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf45b95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_split_the_excel(QA_path):\n",
    "    \"\"\"\n",
    "    :func: 根据xlsx文件获取问题list和答案list（需要更新openyxl）\n",
    "    :param path: 文件路径\n",
    "    :return: 问题list，答案list\n",
    "    \"\"\"\n",
    "    # 读取文件\n",
    "    df1 = pd.read_excel(QA_path)\n",
    "    # 分开\n",
    "    question_list = df1.iloc[:,0].tolist()\n",
    "    answer_list = df1.iloc[:,1].tolist()\n",
    "    # 返回\n",
    "    return question_list,answer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46aafa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试read_and_split_the_excel\n",
    "question_list,answer_list = read_and_split_the_excel(\"../input/uic-cn-admission/CN_QA_dataset_all.xlsx\")\n",
    "display(question_list[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f530b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_split_the_01(zero_one_path):\n",
    "    \"\"\"\n",
    "    :func: 根据xlsx文件获取原始list和测试list和label\n",
    "    :param path: 文件路径\n",
    "    :return: 问题list，答案list\n",
    "    \"\"\"\n",
    "    # 读取文件\n",
    "    df1 = pd.read_csv(zero_one_path)\n",
    "    # 分开\n",
    "    Sen1_list = df1.iloc[:,0].tolist()\n",
    "    Sen2_list = df1.iloc[:,1].tolist()\n",
    "    label_list = df1.iloc[:,2].tolist()\n",
    "    # 返回\n",
    "    return Sen1_list,Sen2_list,label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5432f71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试read_and_split_the_excel\n",
    "Sen1_list, Sen2_list, label_list = read_and_split_the_01(\"../input/01-uic-rm-dup/01_all_rm_dup.csv\")\n",
    "display(Sen1_list[:3])\n",
    "display(Sen2_list[:3])\n",
    "display(label_list[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de6d3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_without_repeated(list_):\n",
    "    temp_list = deepcopy(list_)\n",
    "    m = len(temp_list)\n",
    "    m = m-1\n",
    "    for i_current in range(m,1,-1):\n",
    "        rest = i_current - 1\n",
    "        i_replace = randint(0, rest)\n",
    "#         print(i_current)\n",
    "#         print(i_replace)\n",
    "        temp_list[i_current], temp_list[i_replace] = temp_list[i_replace], temp_list[i_current]\n",
    "    return temp_list\n",
    "    \n",
    "def obtain_shuffle_01(ori_list):\n",
    "    shuffle_q_list = shuffle_without_repeated(ori_list)\n",
    "    \n",
    "    shuffle_label_list = [0]*len(shuffle_q_list)\n",
    "    \n",
    "    return ori_list,shuffle_q_list,shuffle_label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3bc60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the shuffle\n",
    "question_list = ['The cat sits outside',\n",
    "      'A man is playing guitar',\n",
    "      'The new movie is awesome',\n",
    "      'The new opera is nice']\n",
    "obtain_shuffle_01(question_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ff831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_qa_and_expand_training_set(QA_path, zero_one_path):\n",
    "    # get the qa_data\n",
    "    question_list,answer_list = read_and_split_the_excel(QA_path)\n",
    "    # get the 01_data\n",
    "    Sen1_list, Sen2_list, label_list = read_and_split_the_01(zero_one_path)\n",
    "    # get expand 01 data\n",
    "    ori_list,shuffle_q_list,shuffle_label_list = obtain_shuffle_01(question_list)\n",
    "    Sen1_list.extend(ori_list)\n",
    "    Sen2_list.extend(shuffle_q_list)\n",
    "    label_list.extend(shuffle_label_list)\n",
    "    \n",
    "    # get the index of Sen1_list corresponding to the question_list\n",
    "    question_list_index = range(len(question_list))\n",
    "    question_index_dict = dict(zip(question_list,question_list_index))\n",
    "    \n",
    "    Sen1_list_index = []\n",
    "    for i in Sen1_list:\n",
    "        Sen1_list_index.append(question_index_dict[i])\n",
    "        \n",
    "#     print(Sen1_list_index)\n",
    "    \n",
    "    return question_list,answer_list,Sen1_list,Sen1_list_index,Sen2_list,label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c3c2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for getting all the QA data and the zero_one data\n",
    "QA_path = \"../input/uic-cn-admission/CN_QA_dataset_all.xlsx\"\n",
    "zero_one_path = \"../input/01-uic-rm-dup/01_all_rm_dup.csv\"\n",
    "question_list,answer_list,Sen1_list,Sen1_list_index,Sen2_list,label_list = read_qa_and_expand_training_set(QA_path, zero_one_path)\n",
    "\n",
    "# display the sample result\n",
    "display(question_list[:3])\n",
    "display(answer_list[:3])\n",
    "display(Sen1_list[:3])\n",
    "display(Sen1_list_index[:10])\n",
    "display(Sen2_list[:3])\n",
    "display(label_list[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b66bdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# test\n",
    "with tqdm(total=200) as pbar:\n",
    "    pbar.set_description('Processing')\n",
    "    # total表示总的项目, 循环的次数20*10(每次更新数目) = 200(total)\n",
    "    for i in range(20):\n",
    "        # 进行动作, 这里是过0.1s\n",
    "        time.sleep(0.1)\n",
    "        # 进行进度更新, 这里设置10个\n",
    "        pbar.update(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e503f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装包\n",
    "# pip install -U sentence-transformers\n",
    "# pip install -U transformers\n",
    "# pip install openpyxl\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from random import randint\n",
    "from termcolor import colored\n",
    "\n",
    "def SBERT_get_reply(model, query, question_list, answer_list, question_list_emb, topk_SBERT, threshold_SBERT):\n",
    "    # prepared for queries\n",
    "    queries = [query]\n",
    "    query_embeddings = model.encode(queries, convert_to_tensor=True)\n",
    "    if_valid = 0\n",
    "\n",
    "    index_ranked = []\n",
    "    tensor_scores = []\n",
    "\n",
    "    # search the best answer\n",
    "    #     for query, query_embedding in zip(queries, query_embeddings):\n",
    "    cosine_scores = util.pytorch_cos_sim(query_embeddings, question_list_emb)[0]\n",
    "    results = zip(range(len(cosine_scores)), cosine_scores)\n",
    "    # 第一个是按照score排序的index，第二个为对应的score但是是tensor格式\n",
    "    results = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    for index, tensor_score in results:\n",
    "        index_ranked.append(index)\n",
    "        tensor_scores.append(tensor_score)\n",
    "\n",
    "    if tensor_scores[0] > threshold_SBERT:\n",
    "        if_valid = 1\n",
    "\n",
    "#     # 回答答案\n",
    "#     print('top few questions(TFIDF: %d) similar to \"%s\"' % (topk_SBERT, colored(query, 'green')))\n",
    "#     print(\"The best similarity for TF-IDF is:\", tensor_scores[0])\n",
    "\n",
    "    # 得到前几个的index\n",
    "    topk_idx_SBERT = index_ranked[:topk_SBERT]\n",
    "\n",
    "#     for index, idx in enumerate(topk_idx_SBERT):\n",
    "#         print('SBERT; %s\\t%s' % (colored('%.4f' % tensor_scores[index], 'cyan'), colored(question_list[idx], 'yellow')))\n",
    "\n",
    "#     if if_valid:\n",
    "#         print(answer_list[index_ranked[0]])\n",
    "\n",
    "    return if_valid, topk_idx_SBERT, tensor_scores\n",
    "\n",
    "\n",
    "def use_model_qa(model_path, QA_path, zero_one_path):\n",
    "    print(\"数据准备中\")\n",
    "    model = SentenceTransformer(model_path,device='cuda')\n",
    "\n",
    "    topk_SBERT = 3\n",
    "    threshold_SBERT = 0.6\n",
    "\n",
    "    # data embedding\n",
    "    question_list, answer_list = read_and_split_the_excel(QA_path)\n",
    "    question_embeddings = model.encode(question_list, convert_to_tensor=True)\n",
    "    # prepared testing data\n",
    "    question_list,answer_list,Sen1_list,Sen1_list_index,Sen2_list,label_list = read_qa_and_expand_training_set(QA_path, zero_one_path)\n",
    "    \n",
    "    print(\"准备完毕\")\n",
    "    \n",
    "    predict_result = []\n",
    "    \n",
    "#     with tqdm(total=len(Sen1_list)) as pbar:\n",
    "#         pbar.set_description('正在测试')\n",
    "    for index, test_query in enumerate(Sen2_list):\n",
    "\n",
    "        if_valid, topk_idx_SBERT, tensor_scores = SBERT_get_reply(model, test_query, question_list, answer_list, question_embeddings, topk_SBERT, threshold_SBERT)\n",
    "            \n",
    "        if topk_idx_SBERT[0] == Sen1_list_index[index]:\n",
    "            prediction = 1\n",
    "        else:\n",
    "            prediction = 0\n",
    "            \n",
    "        predict_result.append(prediction)\n",
    "            \n",
    "#             print(question_list[topk_idx_TF[0]])\n",
    "#             print(Sen2_list[index])\n",
    "#             print(Sen1_list[index])\n",
    "            \n",
    "#             pbar.update(1)\n",
    "    print(\"Model:\",model_path)\n",
    "    cf_matrix_test,figure_test = performance(label_list,predict_result)\n",
    "    figure_test.show()\n",
    "\n",
    "# # Test for all\n",
    "# print(\"数据准备中\")\n",
    "# model = SentenceTransformer(model_path)\n",
    "\n",
    "# topk_SBERT = 3\n",
    "# threshold_SBERT = 0.7\n",
    "\n",
    "# # data embedding\n",
    "# question_list,answer_list = read_and_split_the_excel(QA_path)\n",
    "# question_embeddings = model.encode(question_list,convert_to_tensor=True)\n",
    "# print(\"准备完毕\")\n",
    "# # 获得问题\n",
    "# q = \"UIC是\"\n",
    "# SBERT_get_reply(model, q, question_list, answer_list, question_embeddings, topk_SBERT, threshold_SBERT)\n",
    "\n",
    "def SBERT_QA_test(model_path):\n",
    "    # model_path = '.\\SBert_CN_fine_tune'\n",
    "    # model_path = '.\\sn_xlm_roberta_base'\n",
    "    # model_path = '.\\deberta_sentence_transformer'\n",
    "\n",
    "    QA_path = \"../input/uic-cn-admission/CN_QA_dataset_all.xlsx\"\n",
    "    zero_one_path = \"../input/01-uic-rm-dup/01_all_rm_dup.csv\"\n",
    "    use_model_qa(model_path, QA_path, zero_one_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c55f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"symanto/sn-xlm-roberta-base-snli-mnli-anli-xnli\"\n",
    "SBERT_QA_test(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d21838",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
